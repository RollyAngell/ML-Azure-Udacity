{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1610863092226
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.31.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1610863185510
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quick-starts-ws-150538\n",
      "aml-quickstarts-150538\n",
      "southcentralus\n",
      "81cefad3-d2c9-4f77-a466-99a7f541c7bb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>HyperDrive-Exp002</td><td>quick-starts-ws-150538</td><td><a href=\"https://ml.azure.com/experiments/id/76e242bf-7eee-4c15-ac7d-11a0b2f05c72?wsid=/subscriptions/81cefad3-d2c9-4f77-a466-99a7f541c7bb/resourcegroups/aml-quickstarts-150538/workspaces/quick-starts-ws-150538&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: HyperDrive-Exp002,\n",
       "Workspace: quick-starts-ws-150538)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a hyperdrive experiment in our workspace\n",
    "\n",
    "# initializing a workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')\n",
    "\n",
    "# choosing a name for experiment\n",
    "experiment_name = 'HyperDrive-Exp002'\n",
    "project_folder = './HyperDrive-pipeline-project'\n",
    "\n",
    "# creating the experiment\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment.start_logging()\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610863799848
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating......\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded..........................................................."
     ]
    }
   ],
   "source": [
    "# creating an AMLCompute cluster for running the experiment\n",
    "\n",
    "# importing required dependencies\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choosing a name for our CPU cluster\n",
    "amlcompute_cluster_name = \"CI-HyperDrive01\"\n",
    "\n",
    "# Verifying that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
    "compute_target.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset that we will be using for this project is the [Heart Failure Prediction](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) dataset from Kaggle, it consist of 12 features.\n",
    "\n",
    "**12 clinical features:**\n",
    "\n",
    "* age - Age\n",
    "\n",
    "* anaemia - Decrease of red blood cells or hemoglobin (boolean)\n",
    "\n",
    "* creatinine_phosphokinase - Level of the CPK enzyme in the blood (mcg/L)\n",
    "\n",
    "* diabetes - If the patient has diabetes (boolean)\n",
    "\n",
    "* ejection_fraction - Percentage of blood leaving the heart at each contraction (percentage)\n",
    "\n",
    "* high_blood_pressure - If the patient has hypertension (boolean)\n",
    "  \n",
    "* platelets - Platelets in the blood (kiloplatelets/mL)\n",
    "\n",
    "* serum_creatinine - Level of serum creatinine in the blood (mg/dL)\n",
    "\n",
    "* serum_sodium - Level of serum sodium in the blood (mEq/L)\n",
    "  \n",
    "* sex - Woman or man (binary)\n",
    "  \n",
    "* smoking - If the patient smokes or not (boolean)\n",
    "\n",
    "* time - Follow-up period (days)\n",
    "\n",
    "\n",
    "We will be predicting the following output:\n",
    "\n",
    "DEATH_EVENT if the patient deceased during the follow-up period (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610864556585
    }
   },
   "outputs": [],
   "source": [
    "# entering the dataset's name and description in 'key' and 'description_text' respectively\n",
    "\n",
    "found = False\n",
    "key = \"Heart Failure Prediction\"\n",
    "description_text = \"Heart Failure Prediction DataSet\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "        print(\"The dataset is loaded\")\n",
    "\n",
    "if not found:\n",
    "        # Creating Dataset and register it into Workspace\n",
    "        example_data = \"https://raw.githubusercontent.com/RollyAngell/ML-Azure-Udacity/main/Project%203%20-%20Casptone%20Project%20AutoML%20vs%20HyperDrive/heart%20failure%20clinical%20records%20dataset.csv\"\n",
    "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \n",
    "        # Registering Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the imported dataset to pandas dataframe for analyzing purpose\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing the dataframe\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "|Setting |Why?|\n",
    "|-|-|\n",
    "|**estimator**| I have defined an SKLearn estimator below as est and I will use it as estimator parameter.|\n",
    "|**hyperparameter_sampling**| It is the sampler that will create the instance of hyperparameters to be used for each sample run. I have defined a RandomParameterSampling below as 'param_sampling' and I will use it as 'hyperparameter_sampling' parameter.|\n",
    "|**policy**|It is the early termination policy that will be used to terminate the experiment if no improvement in primary metric is witnessed after some runs. I have defined a BanditPolicy below as 'et_policy' and I will use it as 'policy' parameter.|\n",
    "|**primary_metric_name**|it is the name of the metric on the basis of which performance of different models will be judged.|\n",
    "|**primary_metric_goal**|In order to get the best model for our classification task, my goal is to maximize the AUC_weighted metric hence I will enter 'PrimaryMetricGoal.MAXIMIZE'as 'primary_metric_goal' parameter.|\n",
    "|**max_total_runs**|It is the maximum number of child runs that will be executed in the experiment to find the best model for the task intended. I will enter '25' as the 'max_total_runs' parameter which will produce a good and acceptable result in less amount of time.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610864621052
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing required dependencies\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.sklearn import SKLearn\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610864664729
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Creating an early termination policy\n",
    "et_policy = BanditPolicy(evaluation_interval=5, slack_factor=None, slack_amount=0.2, delay_evaluation=5)\n",
    "\n",
    "# Creating the different parameters that will be used during training\n",
    "param_sampling = RandomParameterSampling({\"C\": uniform(0.0005, 1.0),\"max_iter\": choice(50, 100, 150, 200, 250)})\n",
    "\n",
    "# Create the environment\n",
    "#sklearn_env = Environment.get(workspace=ws, name=\"AzureML-Tutorial\")\n",
    "#src = ScriptRunConfig(source_directory='.', script='train.py', compute_target = compute_target, environment=sklearn_env)\n",
    "#hyperdrive_run_config = HyperDriveConfig( run_config=src, hyperparameter_sampling=param_sampling, policy=early_termination_policy, primary_metric_name = \"Accuracy\", primary_metric_goal = PrimaryMetricGoal.MAXIMIZE, max_total_runs = 100, max_concurrent_runs = 2)\n",
    "# Creating an estimator and hyperdrive config\n",
    "est = SKLearn(source_directory = 'training', entry_script = 'train.py', compute_target = compute_target)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=est,hyperparameter_sampling=param_sampling,policy=et_policy,primary_metric_name='AUC_weighted',primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,max_total_runs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610864733998
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your experiment\n",
    "run_re = experiment.submit(config = hyperdrive_run_config, show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610864744371
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing required dependencies\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run_re).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610865515571
    }
   },
   "outputs": [],
   "source": [
    "# waiting for completion of run while showing its output\n",
    "run_re.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610865733747
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve best model from Hyperdrive Run\n",
    "\n",
    "# importing required dependencies\n",
    "import joblib\n",
    "\n",
    "best_run = run_re.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "best_run_model = best_run.get_details()['runDefinition']\n",
    "print('Best Run Id:',best_run.id)\n",
    "print('\\n Accuracy:', best_run_metrics['AUC_weighted'])\n",
    "print('\\n parameter values:',parameter_values)\n",
    "print('\\n details:',best_run_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610865754861
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "joblib.dump(best_run_model,'best_hyperdrive_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1610871707592
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current provisioning state of AmlCompute is \"Deleting\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delete compute cluster\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
