{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project.\n",
    "\n",
    "With the help of python notebooks provided in 1st and 2nd project of this nanodegree program ('Optimizing a pipeline in Azure' and 'Operationalizing machine learning'), I have imported following basic dependencies required to complete this project. Any other specific dependecy will be imported as we proceed further in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1610866011944
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.26.0\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from matplotlib import pyplot as pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import pkg_resources\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.pipeline.steps import AutoMLStep\n",
    "\n",
    "# CheckIng core SDK version number\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1610866034952
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aml-02\n",
      "bcp_coe_plioto\n",
      "eastus2\n",
      "eeb1fe4f-1f40-4db4-895a-353699752070\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>AutoML-Exp002</td><td>aml-02</td><td><a href=\"https://ml.azure.com/experiments/id/a9ae8634-5aa0-4bb3-b89d-30222d1778dd?wsid=/subscriptions/eeb1fe4f-1f40-4db4-895a-353699752070/resourcegroups/bcp_coe_plioto/workspaces/aml-02&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: AutoML-Exp002,\n",
       "Workspace: aml-02)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an automl experiment in our workspace\n",
    "\n",
    "# initializing a workspace\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')\n",
    "\n",
    "# choosing a name for experiment\n",
    "experiment_name = 'AutoML-Exp002'\n",
    "project_folder = './AutoML-pipeline-project'\n",
    "\n",
    "# creating the experiment\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment.start_logging()\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1610866655912
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n",
      "Succeeded...................................................................................................................\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Wait timeout has been reached\n",
      "Current provisioning state of AmlCompute is \"Succeeded\" and current node count is \"0\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.core.compute.amlcompute.AmlComputeStatus at 0x7f61adf1c8d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an AMLCompute cluster for running the experiment\n",
    "\n",
    "# importing required dependencies\n",
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choosing a name for our CPU cluster\n",
    "amlcompute_cluster_name = \"CI-AutoML01\"\n",
    "\n",
    "# Verifying that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
    "compute_target.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset that we will be using for this project is the [Heart Failure Prediction](https://www.kaggle.com/andrewmvd/heart-failure-clinical-data) dataset from Kaggle, it consist of 12 features.\n",
    "\n",
    "**12 clinical features:**\n",
    "\n",
    "* age - Age\n",
    "\n",
    "* anaemia - Decrease of red blood cells or hemoglobin (boolean)\n",
    "\n",
    "* creatinine_phosphokinase - Level of the CPK enzyme in the blood (mcg/L)\n",
    "\n",
    "* diabetes - If the patient has diabetes (boolean)\n",
    "\n",
    "* ejection_fraction - Percentage of blood leaving the heart at each contraction (percentage)\n",
    "\n",
    "* high_blood_pressure - If the patient has hypertension (boolean)\n",
    "  \n",
    "* platelets - Platelets in the blood (kiloplatelets/mL)\n",
    "\n",
    "* serum_creatinine - Level of serum creatinine in the blood (mg/dL)\n",
    "\n",
    "* serum_sodium - Level of serum sodium in the blood (mEq/L)\n",
    "  \n",
    "* sex - Woman or man (binary)\n",
    "  \n",
    "* smoking - If the patient smokes or not (boolean)\n",
    "\n",
    "* time - Follow-up period (days)\n",
    "\n",
    "\n",
    "We will be predicting the following output:\n",
    "\n",
    "DEATH_EVENT if the patient deceased during the follow-up period (boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is loaded\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "key = \"Heart Failure Prediction\"\n",
    "description_text = \"Heart Failure Prediction DataSet for Udacity Project 3\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "        found = True\n",
    "        dataset = ws.datasets[key] \n",
    "        print(\"The dataset is loaded\")\n",
    "\n",
    "if not found:\n",
    "        # Creating Dataset and register it into Workspace\n",
    "        data1 = \"https://raw.githubusercontent.com/RollyAngell/ML-Azure-Udacity/main/Project%203%20-%20Casptone%20Project%20AutoML%20vs%20HyperDrive/heart%20failure%20clinical%20records%20dataset.csv\"\n",
    "        dataset = Dataset.Tabular.from_delimited_files(data1)        \n",
    "        # Registering Dataset in Workspace\n",
    "        dataset = dataset.register(workspace=ws,\n",
    "                                   name=key,\n",
    "                                   description=description_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"source\": [\n",
       "    \"https://raw.githubusercontent.com/RollyAngell/ML-Azure-Udacity/main/Project%203%20-%20Casptone%20Project%20AutoML%20vs%20HyperDrive/heart%20failure%20clinical%20records%20dataset.csv\"\n",
       "  ],\n",
       "  \"definition\": [\n",
       "    \"GetFiles\",\n",
       "    \"ParseDelimited\",\n",
       "    \"DropColumns\",\n",
       "    \"SetColumnTypes\"\n",
       "  ],\n",
       "  \"registration\": {\n",
       "    \"id\": \"a7712ae5-e176-4420-98af-e1cef0c5d7c9\",\n",
       "    \"name\": \"Heart Failure Prediction\",\n",
       "    \"version\": 1,\n",
       "    \"description\": \"Heart Failure Prediction DataSet for Udacity Project 3\",\n",
       "    \"workspace\": \"Workspace.create(name='aml-02', subscription_id='eeb1fe4f-1f40-4db4-895a-353699752070', resource_group='bcp_coe_plioto')\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.833893</td>\n",
       "      <td>0.431438</td>\n",
       "      <td>581.839465</td>\n",
       "      <td>0.418060</td>\n",
       "      <td>38.083612</td>\n",
       "      <td>0.351171</td>\n",
       "      <td>263358.029264</td>\n",
       "      <td>1.39388</td>\n",
       "      <td>136.625418</td>\n",
       "      <td>0.648829</td>\n",
       "      <td>0.32107</td>\n",
       "      <td>130.260870</td>\n",
       "      <td>0.32107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.894809</td>\n",
       "      <td>0.496107</td>\n",
       "      <td>970.287881</td>\n",
       "      <td>0.494067</td>\n",
       "      <td>11.834841</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>97804.236869</td>\n",
       "      <td>1.03451</td>\n",
       "      <td>4.412477</td>\n",
       "      <td>0.478136</td>\n",
       "      <td>0.46767</td>\n",
       "      <td>77.614208</td>\n",
       "      <td>0.46767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25100.000000</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>212500.000000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>262000.000000</td>\n",
       "      <td>1.10000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>582.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>303500.000000</td>\n",
       "      <td>1.40000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7861.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>850000.000000</td>\n",
       "      <td>9.40000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
       "count  299.000000  299.000000                299.000000  299.000000   \n",
       "mean    60.833893    0.431438                581.839465    0.418060   \n",
       "std     11.894809    0.496107                970.287881    0.494067   \n",
       "min     40.000000    0.000000                 23.000000    0.000000   \n",
       "25%     51.000000    0.000000                116.500000    0.000000   \n",
       "50%     60.000000    0.000000                250.000000    0.000000   \n",
       "75%     70.000000    1.000000                582.000000    1.000000   \n",
       "max     95.000000    1.000000               7861.000000    1.000000   \n",
       "\n",
       "       ejection_fraction  high_blood_pressure      platelets  \\\n",
       "count         299.000000           299.000000     299.000000   \n",
       "mean           38.083612             0.351171  263358.029264   \n",
       "std            11.834841             0.478136   97804.236869   \n",
       "min            14.000000             0.000000   25100.000000   \n",
       "25%            30.000000             0.000000  212500.000000   \n",
       "50%            38.000000             0.000000  262000.000000   \n",
       "75%            45.000000             1.000000  303500.000000   \n",
       "max            80.000000             1.000000  850000.000000   \n",
       "\n",
       "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
       "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
       "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
       "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
       "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
       "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
       "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
       "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
       "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
       "\n",
       "       DEATH_EVENT  \n",
       "count    299.00000  \n",
       "mean       0.32107  \n",
       "std        0.46767  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        1.00000  \n",
       "max        1.00000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = dataset.to_pandas_dataframe()\n",
    "df_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    203\n",
       "1     96\n",
       "Name: DEATH_EVENT, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_[\"DEATH_EVENT\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "Explain why you chose the automl settings and cofiguration you used below.\n",
    "\n",
    "|Setting |Why?|\n",
    "|-|-|\n",
    "|**experiment_timeout_minutes**|We choose 30 minutos that means the experiment will exit after that time.|\n",
    "|**max_concurrent_iterations**|To get result quickly we choose 5 that means that 5 iterations at the same time.|\n",
    "|**primary_metric**|This is the metric that we want to optimize (accuracy). I will use 'AUC_weighted' as 'primary_metric' parameter. AUC means the area under the Receiver Operating Characteristic Curve which plots the relationship between true positive rate and false positive rate. Since our dataset doesn't have high class imbalance, we can use ROC method for judging the performance of a model. I will use AUC_weighted in order to mitigate the effects of whatever little imbalance is there in the dataset. AUC_weighted is the arithmetic mean of the score for each class, weighted by the number of true instances in each class.|\n",
    "|**task**|classification |\n",
    "|**compute_target**|To define the compute cluster we will be using |\n",
    "|**training_data**|It is the training dataset to be used for the experiment.|\n",
    "|**label_column_name**|To specify the dependent variable that we are trying to classify. I will enter 'DEATH_EVENT' as 'label_column_name' parameter.|\n",
    "|**path**|To specify the dependent variable that we are trying to classify |\n",
    "|**enable_early_stopping**|we can choose to terminate the experiment if the score stops improving in the short term. I will enter 'True' as 'enable_early_stopping' parameter.|\n",
    "|**featurization**|To specify the dependent variable that we are trying to classify |\n",
    "|**debug_log**|To specify the dependent variable that we are trying to classify |\n",
    "|**enable_onnx_compatible_models **|To specify the dependent variable that we are trying to classify |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1610866769545
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\" : 30,\n",
    "    \"max_concurrent_iterations\" : 5,\n",
    "    \"primary_metric\" : 'AUC_weighted'\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(compute_target=compute_target,\n",
    "                            task=\"classification\",\n",
    "                            training_data=dataset,\n",
    "                            label_column_name=\"DEATH_EVENT\",\n",
    "                            path='./AutoML-pipeline-project',\n",
    "                            enable_early_stopping=True,\n",
    "                            featurization='auto',\n",
    "                            enable_onnx_compatible_models=True,\n",
    "                            debug_log=\"automl_errors.log\",\n",
    "                            **automl_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868417207
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n",
      "No run_configuration provided, running on CI-AutoML01 with default configuration\n",
      "Running on remote compute: CI-AutoML01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>AutoML-Exp002</td><td>AutoML_92538d93-6457-4f2f-88c6-8a44ea0fb308</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_92538d93-6457-4f2f-88c6-8a44ea0fb308?wsid=/subscriptions/eeb1fe4f-1f40-4db4-895a-353699752070/resourcegroups/bcp_coe_plioto/workspaces/aml-02&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "              \n",
      "DETAILS:      \n",
      "+---------------------------------+\n",
      "|Number of folds                  |\n",
      "+=================================+\n",
      "|10                               |\n",
      "+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         4   MinMaxScaler RandomForest                      0:01:13       0.9032    0.9032\n",
      "         2   MinMaxScaler RandomForest                      0:01:45       0.9133    0.9133\n",
      "         0   MaxAbsScaler LightGBM                          0:01:27       0.8841    0.9133\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:05:38       0.8847    0.9133\n",
      "         6   StandardScalerWrapper RandomForest             0:02:02       0.8823    0.9133\n",
      "         3   RobustScaler ExtremeRandomTrees                0:04:43       0.8782    0.9133\n",
      "         8   MinMaxScaler ExtremeRandomTrees                0:00:44       0.8640    0.9133\n",
      "         7   MinMaxScaler ExtremeRandomTrees                0:01:14       0.8950    0.9133\n",
      "         5   MinMaxScaler RandomForest                      0:06:06       0.8918    0.9133\n",
      "         9   SparseNormalizer KNN                           0:00:40       0.7496    0.9133\n",
      "        10   MinMaxScaler ExtremeRandomTrees                0:00:45       0.8649    0.9133\n",
      "        13   StandardScalerWrapper SGD                      0:01:02       0.8700    0.9133\n",
      "        11   RobustScaler ExtremeRandomTrees                0:02:23       0.8952    0.9133\n",
      "        14   RobustScaler RandomForest                      0:01:11       0.8998    0.9133\n",
      "        15   StandardScalerWrapper KNN                      0:00:58       0.5203    0.9133\n",
      "        16   MinMaxScaler RandomForest                      0:03:28       0.8814    0.9133\n",
      "        18   MaxAbsScaler RandomForest                      0:02:22       0.8941    0.9133\n",
      "        12   StandardScalerWrapper RandomForest             0:07:17       0.9002    0.9133\n",
      "        17   MinMaxScaler ExtremeRandomTrees                0:04:09       0.8170    0.9133\n"
     ]
    }
   ],
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(config = automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868717293
    }
   },
   "outputs": [],
   "source": [
    "# waiting for completion of remote_run while showing its output\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868834485
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing required dependencies\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868946612
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve best model from AutoML Run\n",
    "\n",
    "# importing required dependencies\n",
    "import joblib\n",
    "\n",
    "best_automl_run, best_automl_fitted_model = remote_run.get_output()\n",
    "print(best_automl_run)\n",
    "print(best_automl_fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868966185
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "joblib.dump(best_automl_fitted_model,'best_automl_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868971395
    }
   },
   "outputs": [],
   "source": [
    "# getting the details of the best model produced by automl\n",
    "best_automl_run.get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610868994344
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def print_model(model,prefix=\"\"):\n",
    "    for step in model.steps:\n",
    "        print(prefix+step[0])\n",
    "        if hasattr(step[1],'estimators') and hasattr(step[1],'weights'):\n",
    "            pprint({'estimators':list(e[0] for e in step[1].estimators), 'weights':step[1].weights})\n",
    "            print()\n",
    "            for estimator in step[1].estimators:\n",
    "                print_model(estimator[1],estimator[0]+'-')\n",
    "        else:\n",
    "            pprint(step[1].get_params())\n",
    "            print()\n",
    "\n",
    "print_model(best_automl_fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610869118916
    }
   },
   "outputs": [],
   "source": [
    "# retrieving the best model as ONNX model\n",
    "best_auto_run, best_onnx_model = remote_run.get_output(return_onnx_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610869141977
    }
   },
   "outputs": [],
   "source": [
    "# importing required dependencies\n",
    "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
    "\n",
    "# saving the best model as onnx_model\n",
    "onnx_fl_path = \"./best_model.onnx\"\n",
    "OnnxConverter.save_onnx_model(best_onnx_model, onnx_fl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610870160746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# registering the best automl model\n",
    "\n",
    "description = 'heart failure predictions'\n",
    "tags = None\n",
    "\n",
    "model = remote_run.register_model(description = description, tags = tags)\n",
    "\n",
    "print(remote_run.model_id)\n",
    "\n",
    "# importing required dependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# loading a curated environment from workspace\n",
    "\n",
    "env = Environment.get(ws, \"AzureML-AutoML\")\n",
    "\n",
    "# specifying scikit-learn as dependency\n",
    "for pip_package in [\"scikit-learn\"]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "# creating an inference config\n",
    "inference_config = InferenceConfig(entry_script='entry_script.py', environment=env)\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1, enable_app_insights = True)\n",
    "\n",
    "# naming the service to be deployed\n",
    "aci_service_name = 'automl-heart-failure-predictions'\n",
    "print(aci_service_name)\n",
    "\n",
    "# deploying the model\n",
    "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
    "aci_service.wait_for_deployment(show_output = True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610870221080
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing required dependencies\n",
    "from numpy import array\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# creating a test sample\n",
    "data = {\"data\": [{\"age\":60.000000,\"anaemia\":0.000000,\"creatinine_phosphokinase\":250.000000,\"diabetes\":0.000000,\"ejection_fraction\":38.000000,\"high_blood_pressure\":0.000000,\"platelets\":262000.000000,\"serum_creatinine\":1.10000,\"serum_sodium\":137.000000,\"sex\":1.000000,\"smoking\":0.00000,\"time\":115.000000}]}\n",
    "td = json.dumps(data)\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# sending request to test the deployed webservice\n",
    "resp = requests.post(aci_service.scoring_uri, td, headers=headers)\n",
    "print(resp.json())\n",
    "y_pred = (json.loads(resp.text))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610871382502
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# printing the logs of deployed web service\n",
    "dep_logs = aci_service.get_logs()\n",
    "for l in dep_logs.split('\\n'):\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610871657577
    }
   },
   "outputs": [],
   "source": [
    "# deleting a web service\n",
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1610871701038
    }
   },
   "outputs": [],
   "source": [
    "# delete compute cluster\n",
    "compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
